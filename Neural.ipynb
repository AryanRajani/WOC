{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HJXCDiwOeUa",
        "outputId": "82a5534c-5cd0-4c7e-da72-0ab326645c83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Importing the required libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the csv files into dataframes (both train and test)\n",
        "\n",
        "emnisttrain = pd.read_csv(\"/content/drive/MyDrive/WOC/emnist-letters-train.csv\", header=None)\n",
        "emnisttest = pd.read_csv(\"/content/drive/MyDrive/WOC/emnist-letters-test.csv\", header=None)"
      ],
      "metadata": {
        "id": "DHk1A-UnOmeI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Functions\n",
        "\n",
        "def importing(dataframe, examples):\n",
        "    X = dataframe.iloc[:examples,1:].transpose() #784x4000\n",
        "    features = X.shape[0]\n",
        "    examples = X.shape[1]\n",
        "    Y = dataframe.iloc[:examples,0].to_numpy()\n",
        "    return X, Y, features, examples\n",
        "\n",
        "Xtrain_emnist, Ytrain_emnist, trainfeatures_emnist, trainexamples_emnist = importing(emnisttrain, 88800)\n",
        "Xtest_emnist, Ytest_emnist, testfeatures_emnist, testexamples = importing(emnisttest, 14800)\n",
        "\n",
        "def scaling(X):\n",
        "    X = X.div(255)\n",
        "    X = X.to_numpy()\n",
        "    return X\n",
        "\n",
        "Xtrain_emnist = scaling(Xtrain_emnist)\n",
        "Xtest_emnist = scaling(Xtest_emnist)\n",
        "\n",
        "def sigmoid(X, theta, bias):\n",
        "  z = np.dot(theta, X) + bias\n",
        "  return 1/(1+np.exp(-z))\n",
        "\n",
        "def onevsall(Y, examples):\n",
        "  Yzeros = np.zeros((examples, 26))\n",
        "  for i in range(examples):\n",
        "    val = Y[i] - 1\n",
        "    Yzeros[i][val] = 1\n",
        "  Y = Yzeros\n",
        "  return Y.T\n",
        "\n",
        "Ytrain_emnist = onevsall(Ytrain_emnist, trainexamples_emnist)"
      ],
      "metadata": {
        "id": "229YewInPpHL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def neural(X, Y, theta, examples):\n",
        "#   z = np.concatenate((np.array([1 for i in range(examples)]).reshape(1,examples),np.dot(theta.T, X))) #17x4000\n",
        "#   layer = sigmoid(z)"
      ],
      "metadata": {
        "id": "xsnb_unzRsZL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# elementslayer2 = 16\n",
        "# theta1 = np.random.randn(trainfeatures_emnist, elementslayer2) #784x100\n",
        "# z = neural(Xtrain_emnist, Ytrain_emnist, theta1)\n",
        "# print(z.shape)"
      ],
      "metadata": {
        "id": "EKPV5MrF6oH-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class neural:\n",
        "#   def __init__(self, X, Y, theta, learningrate, iteration, examples, nooflayers, layersize):\n",
        "#     self.X = X\n",
        "#     self.Y = Y\n",
        "#     self.theta = theta\n",
        "#     self.learningrate = learningrate\n",
        "#     self.iteration = iteration\n",
        "#     self.examples = self.X.shape[1]\n",
        "#     self.nooflayers = nooflayers\n",
        "#     self.layersize = layersize\n",
        "#   def onevsall(self):\n",
        "#     Yzeros = np.zeros((self.examples, 26))\n",
        "#     for i in range(self.examples):\n",
        "#         val = self.Y[i] - 1\n",
        "#         Yzeros[i][val] = 1\n",
        "#     self.Y = Yzeros\n",
        "#     return self.Y\n",
        "#   def sigmoid(self):\n",
        "#     outp = 1/(1+np.exp(-self.X))\n",
        "#   def derivativesigmoid(self):\n",
        "#     return self.sigmoid() * (1 - self.sigmoid())\n",
        "#   def layers(self, inp):\n",
        "#     self.inp = inp\n",
        "#     z = np.concatenate((np.array([1 for i in range(self.examples)]).reshape(1,self.examples),np.dot(self.theta.T, self.inp))) #100x4000\n",
        "#     layer = self.sigmoid(z)\n",
        "#     return layer\n",
        "#   def forward(self):\n",
        "#     self.theta = np.random.randn(self.X.shape[0], self.layersize[0])\n",
        "#     layer = self.layers(self.X)\n",
        "#     for i in range(self.nooflayers):\n",
        "#       self.theta = np.random.randn(self.layersize[i]-1, self.layersize[i+1])\n",
        "#       layer.append(self.layers(self.inp))\n",
        "#     return layer\n",
        "#   def backward(self):\n",
        "#     self.Y = self.onevsall()\n",
        "#     self.ypred = self.forward()\n",
        "#     der_output = np.dot(self.forward(), (self.Y - self.ypred) * self.derivativesigmoid())\n",
        "    "
      ],
      "metadata": {
        "id": "q6ZgklIY71gv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class NeuralNetwork:\n",
        "#     def __init__(self):\n",
        "#         self.wij   = np.random.rand(784,100) # input to hidden layer weights\n",
        "#         self.wjk   = np.random.rand(100,26) # hidden layer to output weights\n",
        "        \n",
        "#     def sigmoid(self, x, w):\n",
        "#         z = np.dot(x, w)\n",
        "#         return 1/(1 + np.exp(-z))\n",
        "    \n",
        "#     def sigmoid_derivative(self, x, w):\n",
        "#         return self.sigmoid(x, w) * (1 - self.sigmoid(x, w))\n",
        "    \n",
        "#     def gradient_descent(self, x, y, iterations):\n",
        "#         for i in range(iterations):\n",
        "#             Xi = x\n",
        "#             Xj = self.sigmoid(Xi, self.wij)\n",
        "#             yhat = self.sigmoid(Xj, self.wjk)\n",
        "#             # gradients for hidden to output weights\n",
        "#             g_wjk = np.dot(Xj.T, (y - yhat) * self.sigmoid_derivative(Xj, self.wjk))\n",
        "#             # gradients for input to hidden weights\n",
        "#             g_wij = np.dot(Xi.T, np.dot((y - yhat) * self.sigmoid_derivative(Xj, self.wjk), self.wjk.T) * self.sigmoid_derivative(Xi, self.wij))\n",
        "#             # update weights\n",
        "#             self.wij -= 0.5*g_wij\n",
        "#             self.wjk -= 0.5*g_wjk\n",
        "#         print('The final prediction from neural network are: ')\n",
        "#         print(yhat)\n",
        "\n",
        "# neural_network = NeuralNetwork()\n",
        "# print('Random starting input to hidden weights: ')\n",
        "# print(neural_network.wij)\n",
        "# print('Random starting hidden to output weights: ')\n",
        "# print(neural_network.wjk)\n",
        "# X = Xtrain_emnist.T\n",
        "# y = Ytrain_emnist\n",
        "# neural_network.gradient_descent(X, y, 1)"
      ],
      "metadata": {
        "id": "QrpKB6SCqwp5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.wij = np.random.randn(100,784)\n",
        "    self.wjk = np.random.randn(26,100)\n",
        "    self.b1 = np.zeros((100,1))\n",
        "    self.b2 = np.zeros((26,1))\n",
        "    self.examples = Xtrain_emnist.shape[1]\n",
        "\n",
        "  def sigmoid(self, X, theta, bias):\n",
        "    z = np.dot(theta, X) + bias\n",
        "    return 1/(1+np.exp(-z))\n",
        "\n",
        "  def derivativesigmoid(self, X, theta):\n",
        "    return self.sigmoid(X, theta) * (1 - self.sigmoid(X, theta))\n",
        "  \n",
        "  def model(self, X, Y, lr, iteration):\n",
        "    costlist = []\n",
        "    for i in range(iteration):\n",
        "      Xi = X\n",
        "      Xj = self.sigmoid(Xi, self.wij, self.b1)\n",
        "      ypred = self.sigmoid(Xj, self.wjk, self.b2)\n",
        "      cost = (-1/trainexamples_emnist) * (np.sum(Y*np.log(ypred) + (1-Y)*np.log(1-ypred)))\n",
        "      costlist.append(cost)\n",
        "      dz2 = ypred - Y\n",
        "      dw2 = 1/self.examples * np.dot(dz2, Xj.T)\n",
        "      db2 = 1/self.examples * np.sum(dz2, axis = 1, keepdims=True)\n",
        "      dz1 = 1/self.examples * np.dot(self.wjk.T, dz2) * (Xj) * (1 - Xj)\n",
        "      dw1 = 1/self.examples * np.dot(dz1, Xi.T)\n",
        "      db1 = 1/self.examples * np.sum(dz1, axis = 1, keepdims=True)\n",
        "      self.wij -= lr * dw1\n",
        "      self.wjk -= lr * dw2\n",
        "      self.b1 -= lr * db1\n",
        "      self.b2 -= lr * db2\n",
        "    print(ypred.shape)\n",
        "    return ypred, self.wij, self.wjk, self.b1, self.b2"
      ],
      "metadata": {
        "id": "S4D8TTNXuoPy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn = NeuralNetwork()\n",
        "ypred, thetaij, thetajk, biasij, biasjk = nn.model(Xtrain_emnist, Ytrain_emnist, 1, 500)"
      ],
      "metadata": {
        "id": "3W9zDlunEqdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy():\n",
        "  Y_pred = np.argmax(ypred, axis=0) + 1\n",
        "  Y_check = Y_pred - emnisttrain.iloc[:88800,0].to_numpy()\n",
        "  accuracy = Y_check.tolist().count(0)/88800*100\n",
        "  return accuracy, Y_pred\n",
        "accuracy, Y_pred = accuracy()\n",
        "accuracy"
      ],
      "metadata": {
        "id": "_LiCg0BxIEPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred"
      ],
      "metadata": {
        "id": "DiFL5WMQE6Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_final(X, Y):\n",
        "  Xi = X\n",
        "  Xj = sigmoid(Xi, thetaij, biasij)\n",
        "  y_final = sigmoid(Xj, thetajk, biasjk)\n",
        "  Y_pred = np.argmax(y_final, axis=0) + 1\n",
        "  Y_check = -(Y_pred - Y)\n",
        "  accuracy = Y_check.tolist().count(0)/len(Y)*100\n",
        "  return accuracy, Y_check, Y_pred\n",
        "accuracy, Y_check, Y_pred = accuracy_final(Xtest_emnist, Ytest_emnist)\n",
        "accuracy"
      ],
      "metadata": {
        "id": "3M0kEpi3LU6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class Neural:\n",
        "\n",
        "#   def __init__(self, X, Y, hiddennodes):\n",
        "\n",
        "#     self.X = X\n",
        "#     self.Y = Y\n",
        "#     self.inputnodes = self.X.shape[0]\n",
        "#     self.examples = self.X.shape[1]\n",
        "#     self.hiddennodes = hiddennodes\n",
        "#     self.outputnodes = 26\n",
        "\n",
        "#     self.layers = [self.inputnodes] + self.hiddennodes + [self.outputnodes]\n",
        "#     self.activations = {0:[]}\n",
        "#     self.activations[0] = self.X\n",
        "\n",
        "#     self.derivatives = {}\n",
        "\n",
        "#     self.weights = {}\n",
        "#     for i in range(len(self.layers) - 1):\n",
        "#       theta = np.random.randn(self.layers[i], self.layers[i+1])\n",
        "#       self.weights[i] = (theta)\n",
        "  \n",
        "#     bias = np.ones((1,self.examples))\n",
        "\n",
        "#   def sigmoid(self, x, w):\n",
        "#     z = np.dot(w.T, x)\n",
        "#     return 1/(1+np.exp(-z))\n",
        "  \n",
        "#   def pdsigmoid(self, x, w):\n",
        "#     return self.sigmoid(x, w) * (1 - self.sigmoid(x, w))\n",
        "  \n",
        "#   def model(self, lr, iteration):\n",
        "    \n",
        "#     for i in range(iteration):\n",
        "\n",
        "#       for i in range(len(self.layers) - 2):\n",
        "#         self.activations[i+1] = (self.sigmoid(self.activations[i], self.weights[i]))\n",
        "      \n",
        "#       ypred = self.sigmoid(self.activations[len(self.layers) - 2], self.weights[len(self.layers) - 2])\n",
        "#       self.activations[len(self.layers)-1] = ypred\n",
        "\n",
        "#       cost = -(1/self.examples) * np.sum(self.Y * np.log(ypred) + (1-self.Y) * (np.log(1 - ypred)))\n",
        "\n",
        "#       for i in range(len(self.layers) - 2):\n",
        "        \n",
        "#         self.weights[len(self.layers)-2-i] -= lr * self.derivatives[len(self.layers)-2-i]\n",
        "\n",
        "#     return self.weights"
      ],
      "metadata": {
        "id": "44lryWDxdAXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nn = Neural(Xtrain_emnist, Ytrain_emnist, [100,50])\n",
        "# nn.model(0.003, 100)"
      ],
      "metadata": {
        "id": "ikJpKMKUH5Mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "92Plv71hYjJU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}